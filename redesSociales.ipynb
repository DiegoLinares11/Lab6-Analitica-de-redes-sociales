{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e9ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, math, string, unicodedata, collections, itertools, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import networkx as nx\n",
    "import community as community_louvain  # paquete python-louvain\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Config general de plots\n",
    "plt.rcParams[\"figure.figsize\"] = (8,4)\n",
    "plt.rcParams[\"axes.grid\"] = True\n",
    "\n",
    "DATA_PATH = \"data/traficogt.txt\"   # <- AJUSTA si es necesario\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl_in_chunks(path, max_rows=None, chunk_size=10000):\n",
    "    \"\"\"\n",
    "    Lee un JSONL pesado en bloques, devuelve DataFrame con columnas clave ya extraídas.\n",
    "    max_rows: si quieres muestrear por desarrollo (e.g., 50_000); None = todo.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if max_rows is not None and i >= max_rows:\n",
    "                break\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "            # Campos principales\n",
    "            row = {\n",
    "                \"id\": obj.get(\"id\"),\n",
    "                \"date\": obj.get(\"date\"),\n",
    "                \"lang\": obj.get(\"lang\"),\n",
    "                \"rawContent\": obj.get(\"rawContent\") or \"\",\n",
    "                \"replyCount\": obj.get(\"replyCount\"),\n",
    "                \"retweetCount\": obj.get(\"retweetCount\"),\n",
    "                \"likeCount\": obj.get(\"likeCount\"),\n",
    "                \"quoteCount\": obj.get(\"quoteCount\"),\n",
    "                \"viewCount\": obj.get(\"viewCount\"),\n",
    "                \"sourceLabel\": (obj.get(\"sourceLabel\") or obj.get(\"source\")),\n",
    "            }\n",
    "\n",
    "            # Usuario autor\n",
    "            u = obj.get(\"user\") or {}\n",
    "            row.update({\n",
    "                \"user_id\": u.get(\"id\"),\n",
    "                \"username\": (u.get(\"username\") or \"\").lower(),\n",
    "                \"displayname\": u.get(\"displayname\") or \"\",\n",
    "                \"user_followers\": u.get(\"followersCount\"),\n",
    "                \"user_friends\": u.get(\"friendsCount\"),\n",
    "            })\n",
    "\n",
    "            # Menciones (lista de objetos con username/displayname) -> guardamos usernames (lower)\n",
    "            mentioned = obj.get(\"mentionedUsers\") or []\n",
    "            row[\"mentions\"] = [ (mu.get(\"username\") or \"\").lower()\n",
    "                                for mu in mentioned if mu and mu.get(\"username\") ]\n",
    "\n",
    "            # Hashtags si existieran (como no me puse a ver todo el JSON, asumo que es lista de strings)\n",
    "            row[\"hashtags\"] = [h.lower() for h in (obj.get(\"hashtags\") or [])]\n",
    "\n",
    "            # Retweet/Reply/Quote (heurísticas)\n",
    "            row[\"is_retweet\"] = obj.get(\"retweetedTweet\") is not None\n",
    "            row[\"is_quote\"]   = obj.get(\"quotedTweet\") is not None\n",
    "\n",
    "            # Reply detectado por metadata si existe; si no, por texto que inicia con @\n",
    "            row[\"is_reply\"] = False\n",
    "            if obj.get(\"inReplyToTweetId\") or obj.get(\"inReplyToUser\"):\n",
    "                row[\"is_reply\"] = True\n",
    "            else:\n",
    "                # fallback textual\n",
    "                row[\"is_reply\"] = bool(re.match(r\"^\\s*@\\w+\", row[\"rawContent\"]))\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if not df.empty:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\", utc=True)\n",
    "    return df\n",
    "\n",
    "# TIP para desarrollo: usa max_rows para iterar rápido; luego quítalo para el corrida final.\n",
    "df = read_jsonl_in_chunks(DATA_PATH, max_rows=None)\n",
    "df.info()\n",
    "df.head(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
